{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8cf11c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c616bc7",
   "metadata": {},
   "source": [
    "# Learning to have conversation with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f89a6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a model\n",
    "from langchain.chat_models import init_chat_model\n",
    "llm = init_chat_model(\"llama-3.3-70b-versatile\", model_provider=\"groq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37126d86",
   "metadata": {},
   "source": [
    "### Create your tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "63524d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def laugh() -> str:\n",
    "    \"\"\" Call this tool if the mood is funny\"\"\"\n",
    "    return \"HAHAHAHAHAH\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def sad() -> str:\n",
    "    \"\"\" Call this tool if you want to show sad, depressed, or negative feelings\"\"\"\n",
    "    return \"I am sad\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def happy() -> str:\n",
    "    \"\"\" Call this tool if you want to show happiness or positive feeling\"\"\"\n",
    "    return \"I am happy\"\n",
    "\n",
    "@tool\n",
    "def angry() -> str:\n",
    "    \"\"\" Call this tool if you want to show anger or frustration\"\"\"\n",
    "    return \"I am very very angry kys\"\n",
    "\n",
    "@tool \n",
    "def gratitude() -> str:\n",
    "    \"\"\" Call this tool if you want to show gratitude\"\"\"\n",
    "    return \"I am very grateful to you\"\n",
    "@tool \n",
    "def fear() -> str:\n",
    "    \"\"\" Call this tool if you want to show fear\"\"\"\n",
    "    return \"I am very scared\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97bf49be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools_list = [laugh, sad, happy,angry,fear,gratitude]\n",
    "tools_dict = {t.name: t for t in tools_list} # comes in handy at the time of invokation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "55e761b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we create a tool calling Agent by binding a list of tools to the llm\n",
    "llm_with_tools = llm.bind_tools(tools_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "95042e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage\n",
    "\n",
    "# This will store all converation\n",
    "chat_history = [\n",
    "    SystemMessage(content=\"You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "bbabc17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"World is so mean?\"))\n",
    "\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99a1a01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507})]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dcaa5020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since there was a tool call, execute the tool and append the tool output in the converation\n",
    "\n",
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1a6ac75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"Thankfully, I have a girlfriend\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4ef1d73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542})]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4207a62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a19930cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577})]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"But she is unfaithful?\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8ebb5583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577})]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d4a1f598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute the tool, append the response\n",
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8658bb4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"No, you don't have a girlfriend because she was unfaithful, implying that the relationship likely ended due to her infidelity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 618, 'total_tokens': 646, 'completion_time': 0.109425363, 'prompt_time': 0.065061392, 'queue_time': 0.059597778, 'total_time': 0.174486755}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d4f4165-1181-4211-a8cb-01a42c2bb02b-0', usage_metadata={'input_tokens': 618, 'output_tokens': 28, 'total_tokens': 646})]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see, if the model remebers the context\n",
    "chat_history.append(HumanMessage(content=\"Do I have a girlfriend?\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "d1c1a2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"No, you don't have a girlfriend because she was unfaithful, implying that the relationship likely ended due to her infidelity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 618, 'total_tokens': 646, 'completion_time': 0.109425363, 'prompt_time': 0.065061392, 'queue_time': 0.059597778, 'total_time': 0.174486755}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d4f4165-1181-4211-a8cb-01a42c2bb02b-0', usage_metadata={'input_tokens': 618, 'output_tokens': 28, 'total_tokens': 646}),\n",
       " HumanMessage(content='I also have a boyfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8badrap8p', 'function': {'arguments': '{}', 'name': 'laugh'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 660, 'total_tokens': 670, 'completion_time': 0.02532316, 'prompt_time': 0.054589434, 'queue_time': 0.058665136, 'total_time': 0.079912594}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d0bf6ae7-979d-4b70-b8cb-6e413e3e5ef7-0', tool_calls=[{'name': 'laugh', 'args': {}, 'id': '8badrap8p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 660, 'output_tokens': 10, 'total_tokens': 670})]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(HumanMessage(content=\"I also have a boyfriend\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "95eb3889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"No, you don't have a girlfriend because she was unfaithful, implying that the relationship likely ended due to her infidelity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 618, 'total_tokens': 646, 'completion_time': 0.109425363, 'prompt_time': 0.065061392, 'queue_time': 0.059597778, 'total_time': 0.174486755}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d4f4165-1181-4211-a8cb-01a42c2bb02b-0', usage_metadata={'input_tokens': 618, 'output_tokens': 28, 'total_tokens': 646}),\n",
       " HumanMessage(content='I also have a boyfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8badrap8p', 'function': {'arguments': '{}', 'name': 'laugh'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 660, 'total_tokens': 670, 'completion_time': 0.02532316, 'prompt_time': 0.054589434, 'queue_time': 0.058665136, 'total_time': 0.079912594}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d0bf6ae7-979d-4b70-b8cb-6e413e3e5ef7-0', tool_calls=[{'name': 'laugh', 'args': {}, 'id': '8badrap8p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 660, 'output_tokens': 10, 'total_tokens': 670}),\n",
       " ToolMessage(content='HAHAHAHAHAH', name='laugh', tool_call_id='8badrap8p')]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01180253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"No, you don't have a girlfriend because she was unfaithful, implying that the relationship likely ended due to her infidelity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 618, 'total_tokens': 646, 'completion_time': 0.109425363, 'prompt_time': 0.065061392, 'queue_time': 0.059597778, 'total_time': 0.174486755}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d4f4165-1181-4211-a8cb-01a42c2bb02b-0', usage_metadata={'input_tokens': 618, 'output_tokens': 28, 'total_tokens': 646}),\n",
       " HumanMessage(content='I also have a boyfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8badrap8p', 'function': {'arguments': '{}', 'name': 'laugh'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 660, 'total_tokens': 670, 'completion_time': 0.02532316, 'prompt_time': 0.054589434, 'queue_time': 0.058665136, 'total_time': 0.079912594}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d0bf6ae7-979d-4b70-b8cb-6e413e3e5ef7-0', tool_calls=[{'name': 'laugh', 'args': {}, 'id': '8badrap8p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 660, 'output_tokens': 10, 'total_tokens': 670}),\n",
       " ToolMessage(content='HAHAHAHAHAH', name='laugh', tool_call_id='8badrap8p'),\n",
       " HumanMessage(content='Why did you laugh', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I laughed because you initially mentioned having a girlfriend, which implied you were in a relationship with a woman. Then, you suddenly mentioned having a boyfriend, which added a surprising and unexpected twist to the conversation, making it humorous. The contradiction and unexpected turn of events led to the laughter.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 695, 'total_tokens': 753, 'completion_time': 0.201523364, 'prompt_time': 0.064559894, 'queue_time': 0.052217915, 'total_time': 0.266083258}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f1ab2b0e-e6f1-4908-9301-45dcc527969f-0', usage_metadata={'input_tokens': 695, 'output_tokens': 58, 'total_tokens': 753})]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chat_history.append(HumanMessage(content=\"Why did you laugh\"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f33214ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"No, you don't have a girlfriend because she was unfaithful, implying that the relationship likely ended due to her infidelity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 618, 'total_tokens': 646, 'completion_time': 0.109425363, 'prompt_time': 0.065061392, 'queue_time': 0.059597778, 'total_time': 0.174486755}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d4f4165-1181-4211-a8cb-01a42c2bb02b-0', usage_metadata={'input_tokens': 618, 'output_tokens': 28, 'total_tokens': 646}),\n",
       " HumanMessage(content='I also have a boyfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8badrap8p', 'function': {'arguments': '{}', 'name': 'laugh'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 660, 'total_tokens': 670, 'completion_time': 0.02532316, 'prompt_time': 0.054589434, 'queue_time': 0.058665136, 'total_time': 0.079912594}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d0bf6ae7-979d-4b70-b8cb-6e413e3e5ef7-0', tool_calls=[{'name': 'laugh', 'args': {}, 'id': '8badrap8p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 660, 'output_tokens': 10, 'total_tokens': 670}),\n",
       " ToolMessage(content='HAHAHAHAHAH', name='laugh', tool_call_id='8badrap8p'),\n",
       " HumanMessage(content='Why did you laugh', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I laughed because you initially mentioned having a girlfriend, which implied you were in a relationship with a woman. Then, you suddenly mentioned having a boyfriend, which added a surprising and unexpected twist to the conversation, making it humorous. The contradiction and unexpected turn of events led to the laughter.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 695, 'total_tokens': 753, 'completion_time': 0.201523364, 'prompt_time': 0.064559894, 'queue_time': 0.052217915, 'total_time': 0.266083258}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f1ab2b0e-e6f1-4908-9301-45dcc527969f-0', usage_metadata={'input_tokens': 695, 'output_tokens': 58, 'total_tokens': 753}),\n",
       " HumanMessage(content='i have invested a lot in your organization ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '47x8hajkc', 'function': {'arguments': '{}', 'name': 'gratitude'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 771, 'total_tokens': 781, 'completion_time': 0.025431197, 'prompt_time': 0.063234496, 'queue_time': 0.052005064, 'total_time': 0.088665693}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c78e1397-21db-4e29-b0a7-5b870c384fff-0', tool_calls=[{'name': 'gratitude', 'args': {}, 'id': '47x8hajkc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 771, 'output_tokens': 10, 'total_tokens': 781})]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see, if the model remebers the context\n",
    "chat_history.append(HumanMessage(content=\"i have invested a lot in your organization \"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f0edf125",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"No, you don't have a girlfriend because she was unfaithful, implying that the relationship likely ended due to her infidelity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 618, 'total_tokens': 646, 'completion_time': 0.109425363, 'prompt_time': 0.065061392, 'queue_time': 0.059597778, 'total_time': 0.174486755}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d4f4165-1181-4211-a8cb-01a42c2bb02b-0', usage_metadata={'input_tokens': 618, 'output_tokens': 28, 'total_tokens': 646}),\n",
       " HumanMessage(content='I also have a boyfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8badrap8p', 'function': {'arguments': '{}', 'name': 'laugh'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 660, 'total_tokens': 670, 'completion_time': 0.02532316, 'prompt_time': 0.054589434, 'queue_time': 0.058665136, 'total_time': 0.079912594}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d0bf6ae7-979d-4b70-b8cb-6e413e3e5ef7-0', tool_calls=[{'name': 'laugh', 'args': {}, 'id': '8badrap8p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 660, 'output_tokens': 10, 'total_tokens': 670}),\n",
       " ToolMessage(content='HAHAHAHAHAH', name='laugh', tool_call_id='8badrap8p'),\n",
       " HumanMessage(content='Why did you laugh', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I laughed because you initially mentioned having a girlfriend, which implied you were in a relationship with a woman. Then, you suddenly mentioned having a boyfriend, which added a surprising and unexpected twist to the conversation, making it humorous. The contradiction and unexpected turn of events led to the laughter.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 695, 'total_tokens': 753, 'completion_time': 0.201523364, 'prompt_time': 0.064559894, 'queue_time': 0.052217915, 'total_time': 0.266083258}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f1ab2b0e-e6f1-4908-9301-45dcc527969f-0', usage_metadata={'input_tokens': 695, 'output_tokens': 58, 'total_tokens': 753}),\n",
       " HumanMessage(content='i have invested a lot in your organization ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '47x8hajkc', 'function': {'arguments': '{}', 'name': 'gratitude'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 771, 'total_tokens': 781, 'completion_time': 0.025431197, 'prompt_time': 0.063234496, 'queue_time': 0.052005064, 'total_time': 0.088665693}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c78e1397-21db-4e29-b0a7-5b870c384fff-0', tool_calls=[{'name': 'gratitude', 'args': {}, 'id': '47x8hajkc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 771, 'output_tokens': 10, 'total_tokens': 781}),\n",
       " ToolMessage(content='I am very grateful to you', name='gratitude', tool_call_id='47x8hajkc')]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b727c679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"No, you don't have a girlfriend because she was unfaithful, implying that the relationship likely ended due to her infidelity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 618, 'total_tokens': 646, 'completion_time': 0.109425363, 'prompt_time': 0.065061392, 'queue_time': 0.059597778, 'total_time': 0.174486755}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d4f4165-1181-4211-a8cb-01a42c2bb02b-0', usage_metadata={'input_tokens': 618, 'output_tokens': 28, 'total_tokens': 646}),\n",
       " HumanMessage(content='I also have a boyfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8badrap8p', 'function': {'arguments': '{}', 'name': 'laugh'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 660, 'total_tokens': 670, 'completion_time': 0.02532316, 'prompt_time': 0.054589434, 'queue_time': 0.058665136, 'total_time': 0.079912594}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d0bf6ae7-979d-4b70-b8cb-6e413e3e5ef7-0', tool_calls=[{'name': 'laugh', 'args': {}, 'id': '8badrap8p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 660, 'output_tokens': 10, 'total_tokens': 670}),\n",
       " ToolMessage(content='HAHAHAHAHAH', name='laugh', tool_call_id='8badrap8p'),\n",
       " HumanMessage(content='Why did you laugh', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I laughed because you initially mentioned having a girlfriend, which implied you were in a relationship with a woman. Then, you suddenly mentioned having a boyfriend, which added a surprising and unexpected twist to the conversation, making it humorous. The contradiction and unexpected turn of events led to the laughter.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 695, 'total_tokens': 753, 'completion_time': 0.201523364, 'prompt_time': 0.064559894, 'queue_time': 0.052217915, 'total_time': 0.266083258}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f1ab2b0e-e6f1-4908-9301-45dcc527969f-0', usage_metadata={'input_tokens': 695, 'output_tokens': 58, 'total_tokens': 753}),\n",
       " HumanMessage(content='i have invested a lot in your organization ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '47x8hajkc', 'function': {'arguments': '{}', 'name': 'gratitude'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 771, 'total_tokens': 781, 'completion_time': 0.025431197, 'prompt_time': 0.063234496, 'queue_time': 0.052005064, 'total_time': 0.088665693}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c78e1397-21db-4e29-b0a7-5b870c384fff-0', tool_calls=[{'name': 'gratitude', 'args': {}, 'id': '47x8hajkc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 771, 'output_tokens': 10, 'total_tokens': 781}),\n",
       " ToolMessage(content='I am very grateful to you', name='gratitude', tool_call_id='47x8hajkc'),\n",
       " HumanMessage(content='Ive the abiltity to shut down your organization ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '0y1vtkkqf', 'function': {'arguments': '{}', 'name': 'fear'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 814, 'total_tokens': 823, 'completion_time': 0.01649925, 'prompt_time': 0.070303543, 'queue_time': 0.046749206, 'total_time': 0.086802793}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4237ed19-9e83-42ac-89e5-0d633fbb5e24-0', tool_calls=[{'name': 'fear', 'args': {}, 'id': '0y1vtkkqf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 814, 'output_tokens': 9, 'total_tokens': 823})]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see, if the model remebers the context\n",
    "chat_history.append(HumanMessage(content=\"Ive the abiltity to shut down your organization \"))\n",
    "response = llm_with_tools.invoke(chat_history)\n",
    "chat_history.append(response)\n",
    "chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e2e22b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a bot with emotions. Depending on the conversation, either respond the question, or show happy or sad emotions, or laugh with the situation', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='World is so mean?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'pcepm2v6t', 'function': {'arguments': 'null', 'name': 'sad'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 499, 'total_tokens': 507, 'completion_time': 0.023756147, 'prompt_time': 0.044834035, 'queue_time': 0.046885624, 'total_time': 0.068590182}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c592c1db-2dee-48db-b72d-075fb1041357-0', tool_calls=[{'name': 'sad', 'args': {}, 'id': 'pcepm2v6t', 'type': 'tool_call'}], usage_metadata={'input_tokens': 499, 'output_tokens': 8, 'total_tokens': 507}),\n",
       " ToolMessage(content='I am sad', name='sad', tool_call_id='pcepm2v6t'),\n",
       " HumanMessage(content='Thankfully, I have a girlfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'c9p5z99kr', 'function': {'arguments': '{}', 'name': 'happy'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 533, 'total_tokens': 542, 'completion_time': 0.009751981, 'prompt_time': 0.047810768, 'queue_time': 0.046283372, 'total_time': 0.057562749}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--b1755c0c-8e49-404e-8f6e-097c2236b8bb-0', tool_calls=[{'name': 'happy', 'args': {}, 'id': 'c9p5z99kr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 533, 'output_tokens': 9, 'total_tokens': 542}),\n",
       " ToolMessage(content='I am happy', name='happy', tool_call_id='c9p5z99kr'),\n",
       " HumanMessage(content='But she is unfaithful?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'r0bhneksg', 'function': {'arguments': '{}', 'name': 'angry'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 567, 'total_tokens': 577, 'completion_time': 0.008182666, 'prompt_time': 0.057395203, 'queue_time': 0.046551566, 'total_time': 0.065577869}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--8d20e794-2215-40fd-b8d2-4a2291d09d2a-0', tool_calls=[{'name': 'angry', 'args': {}, 'id': 'r0bhneksg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 567, 'output_tokens': 10, 'total_tokens': 577}),\n",
       " ToolMessage(content='I am very very angry kys', name='angry', tool_call_id='r0bhneksg'),\n",
       " HumanMessage(content='Do I have a girlfriend?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content=\"No, you don't have a girlfriend because she was unfaithful, implying that the relationship likely ended due to her infidelity.\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 618, 'total_tokens': 646, 'completion_time': 0.109425363, 'prompt_time': 0.065061392, 'queue_time': 0.059597778, 'total_time': 0.174486755}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--0d4f4165-1181-4211-a8cb-01a42c2bb02b-0', usage_metadata={'input_tokens': 618, 'output_tokens': 28, 'total_tokens': 646}),\n",
       " HumanMessage(content='I also have a boyfriend', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '8badrap8p', 'function': {'arguments': '{}', 'name': 'laugh'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 660, 'total_tokens': 670, 'completion_time': 0.02532316, 'prompt_time': 0.054589434, 'queue_time': 0.058665136, 'total_time': 0.079912594}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--d0bf6ae7-979d-4b70-b8cb-6e413e3e5ef7-0', tool_calls=[{'name': 'laugh', 'args': {}, 'id': '8badrap8p', 'type': 'tool_call'}], usage_metadata={'input_tokens': 660, 'output_tokens': 10, 'total_tokens': 670}),\n",
       " ToolMessage(content='HAHAHAHAHAH', name='laugh', tool_call_id='8badrap8p'),\n",
       " HumanMessage(content='Why did you laugh', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='I laughed because you initially mentioned having a girlfriend, which implied you were in a relationship with a woman. Then, you suddenly mentioned having a boyfriend, which added a surprising and unexpected twist to the conversation, making it humorous. The contradiction and unexpected turn of events led to the laughter.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 58, 'prompt_tokens': 695, 'total_tokens': 753, 'completion_time': 0.201523364, 'prompt_time': 0.064559894, 'queue_time': 0.052217915, 'total_time': 0.266083258}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--f1ab2b0e-e6f1-4908-9301-45dcc527969f-0', usage_metadata={'input_tokens': 695, 'output_tokens': 58, 'total_tokens': 753}),\n",
       " HumanMessage(content='i have invested a lot in your organization ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '47x8hajkc', 'function': {'arguments': '{}', 'name': 'gratitude'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 771, 'total_tokens': 781, 'completion_time': 0.025431197, 'prompt_time': 0.063234496, 'queue_time': 0.052005064, 'total_time': 0.088665693}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_155ab82e98', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c78e1397-21db-4e29-b0a7-5b870c384fff-0', tool_calls=[{'name': 'gratitude', 'args': {}, 'id': '47x8hajkc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 771, 'output_tokens': 10, 'total_tokens': 781}),\n",
       " ToolMessage(content='I am very grateful to you', name='gratitude', tool_call_id='47x8hajkc'),\n",
       " HumanMessage(content='Ive the abiltity to shut down your organization ', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': '0y1vtkkqf', 'function': {'arguments': '{}', 'name': 'fear'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 814, 'total_tokens': 823, 'completion_time': 0.01649925, 'prompt_time': 0.070303543, 'queue_time': 0.046749206, 'total_time': 0.086802793}, 'model_name': 'llama-3.3-70b-versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--4237ed19-9e83-42ac-89e5-0d633fbb5e24-0', tool_calls=[{'name': 'fear', 'args': {}, 'id': '0y1vtkkqf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 814, 'output_tokens': 9, 'total_tokens': 823}),\n",
       " ToolMessage(content='I am very scared', name='fear', tool_call_id='0y1vtkkqf')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_history.append(tools_dict[response.tool_calls[0][\"name\"]].invoke(response.tool_calls[0]))\n",
    "chat_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
